name: Mapt Provision Test

on:
  pull_request:
    branches:
      - KFLUXDP-333
    paths:
      - 'tasks/mapt-oci/kind-aws-spot/provision/**'
      - 'tasks/mapt-oci/kind-aws-spot/deprovision/**'
      - '.github/workflows/mapt-provision-test.yaml'
    types:
      - opened
      - synchronize
      - reopened
  merge_group:
    types:
      - checks_requested

# Central configuration for the workflow
env:
  MAPT_ARCH: x86_64
  MAPT_CPUS: 1
  MAPT_MEMORY: 1
  MAPT_SPOT: "true"
  MAPT_SPOT_INCREASE_RATE: 10
  MAPT_TIMEOUT: 15m
  CLUSTER_ID: pr-${{ github.event.number }}-${{ github.run_id }}
  # Define original image names from task files for easy reference
  ORIGINAL_MAPT_IMAGE: quay.io/redhat-developer/mapt:v0.9.7
  ORIGINAL_OC_IMAGE: registry.redhat.io/openshift4/ose-cli:4.13@sha256:e70eb2be867f1236b19f5cbfeb8e0625737ce0ec1369e32a4f9f146aaaf68d49
  # Define public replacement images
  PUBLIC_MAPT_IMAGE: quay.io/konflux-ci/mapt:latest
  PUBLIC_OC_IMAGE: quay.io/openshift/origin-cli:latest

jobs:
  test-provision-deprovision:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: 1. Checkout Repository
        uses: actions/checkout@v4

      - name: 2. Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: 3. Find Cheapest AWS Spot Region for x86_64
        id: cheapest_region
        run: |
          echo "üîé Searching for the cheapest AWS region for a t3.micro (x86_64) spot instance..."
          REGIONS=$(aws ec2 describe-regions --query "Regions[?OptInStatus=='opt-in-not-required' || OptInStatus=='opted-in'].RegionName" --output text)
          BEST_REGION=""
          MIN_PRICE="999.0"
          for REGION in $REGIONS; do
            PRICE=$(aws ec2 describe-spot-price-history --instance-types t3.micro --product-descriptions "Linux/UNIX (Amazon VPC)" --start-time $(date -u +%Y-%m-%dT%H:%M:%SZ) --max-items 1 --region "$REGION" --query "SpotPriceHistory[0].SpotPrice" --output text 2>/dev/null)
            if [ -n "$PRICE" ] && awk -v price="$PRICE" -v min_price="$MIN_PRICE" 'BEGIN {exit !(price < min_price)}'; then
              MIN_PRICE=$PRICE
              BEST_REGION=$REGION
            fi
          done
          if [ -z "$BEST_REGION" ]; then BEST_REGION="us-east-1"; fi
          echo "‚úÖ Cheapest region found: $BEST_REGION at \$${MIN_PRICE}/hour"
          echo "region=${BEST_REGION}" >> $GITHUB_OUTPUT

      - name: 4. Create Temporary S3 Bucket
        id: s3_bucket
        run: |
          BUCKET_NAME="mapt-test-bucket-${{ github.run_id }}-${{ github.run_attempt }}"
          REGION="${{ steps.cheapest_region.outputs.region }}"
          echo "ü™£ Creating S3 bucket '$BUCKET_NAME' in region '$REGION'..."
          if [ "$REGION" = "us-east-1" ]; then
            aws s3api create-bucket --bucket "$BUCKET_NAME" --region "$REGION"
          else
            aws s3api create-bucket --bucket "$BUCKET_NAME" --region "$REGION" --create-bucket-configuration LocationConstraint="$REGION"
          fi
          echo "name=${BUCKET_NAME}" >> $GITHUB_OUTPUT

      - name: 5. Log in to Quay.io
        uses: docker/login-action@v3
        with:
          registry: quay.io

      - name: 6. Pre-pull and Retag Container Images
        run: |
          echo "Pulling public images..."
          docker pull ${{ env.PUBLIC_MAPT_IMAGE }}
          docker pull ${{ env.PUBLIC_OC_IMAGE }}
          
          echo "Retagging images to match original names in task definitions..."
          docker tag ${{ env.PUBLIC_MAPT_IMAGE }} ${{ env.ORIGINAL_MAPT_IMAGE }}
          docker tag ${{ env.PUBLIC_OC_IMAGE }} ${{ env.ORIGINAL_OC_IMAGE }}

      - name: 7. Spin up KinD Cluster and Load Images
        uses: helm/kind-action@v1.10.0
        with:
          version: v0.23.0
          load_docker_images: |
            ${{ env.ORIGINAL_MAPT_IMAGE }}
            ${{ env.ORIGINAL_OC_IMAGE }}
      
      - name: 8. Install Tekton
        run: |
          kubectl apply --filename https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml
          echo "‚è≥ Waiting for Tekton controller and webhook pods to be ready..."
          kubectl wait --for=condition=ready pod -l app=tekton-pipelines-controller -n tekton-pipelines --timeout=300s
          kubectl wait --for=condition=ready pod -l app=tekton-pipelines-webhook -n tekton-pipelines --timeout=300s

      - name: 9. Show Tekton Pod Status on Failure
        if: failure()
        run: |
          echo "::error::Tekton installation failed. Dumping pod status for debugging..."
          kubectl get pods -n tekton-pipelines -o wide
          echo "---"
          kubectl describe pods -n tekton-pipelines
      
      - name: 10. Create Kubernetes Secret for Tekton
        run: |
          kubectl create secret generic aws-credentials --from-literal=access-key="${{ secrets.AWS_ACCESS_KEY_ID }}" --from-literal=secret-key="${{ secrets.AWS_SECRET_ACCESS_KEY }}" --from-literal=region="${{ steps.cheapest_region.outputs.region }}" --from-literal=bucket="${{ steps.s3_bucket.outputs.name }}"
      
      - name: 11. Run Tekton Provision & Deprovision Pipeline
        env:
          CLUSTER_ID: ${{ env.CLUSTER_ID }}
        run: |
          LOWERCASE_CLUSTER_ID=$(echo "$CLUSTER_ID" | tr '[:upper:]' '[:lower:]')

          echo "Waiting for Tekton webhook to become available..."
          kubectl wait --for=condition=Available --timeout=60s deployment/tekton-pipelines-webhook -n tekton-pipelines

          # Apply original, un-patched task files. The images are already in the cluster.
          kubectl apply -f tasks/mapt-oci/kind-aws-spot/provision/0.1/kind-aws-provision.yaml
          kubectl apply -f tasks/mapt-oci/kind-aws-spot/deprovision/0.1/kind-aws-deprovision.yaml

          # Inject the USER env var into the 'provisioner' step (index 1) by patching the deployed Task resource.
          kubectl patch task kind-aws-provision --type='json' -p='[{"op": "add", "path": "/spec/steps/1/env", "value": [{"name": "USER", "value": "tekton"}]}]'

          cat <<EOF | kubectl apply -f -
          apiVersion: tekton.dev/v1
          kind: Pipeline
          metadata:
            name: test-aws-kind-lifecycle
          spec:
            params:
              - name: id
            tasks:
              - name: mapt-provision
                taskRef:
                  name: kind-aws-provision
                params:
                  - name: id
                    value: \$(params.id)
                  - name: secret-aws-credentials
                    value: "aws-credentials"
                  - name: ownerName
                    value: \$(context.pipelineRun.name)
                  - name: ownerUid
                    value: \$(context.pipelineRun.uid)
                  - name: arch
                    value: '${{ env.MAPT_ARCH }}'
                  - name: cpus
                    value: '${{ env.MAPT_CPUS }}'
                  - name: memory
                    value: '${{ env.MAPT_MEMORY }}'
                  - name: spot
                    value: '${{ env.MAPT_SPOT }}'
                  - name: spot-increase-rate
                    value: '${{ env.MAPT_SPOT_INCREASE_RATE }}'
                  - name: timeout
                    value: '${{ env.MAPT_TIMEOUT }}'
                  - name: tags
                    value: "created-by=github-actions"
                  - name: oci-ref
                    value: "not-used"

              - name: mapt-deprovision
                runAfter: ["mapt-provision"]
                taskRef:
                  name: kind-aws-deprovision
                params:
                  - name: id
                    value: \$(params.id)
                  - name: secret-aws-credentials
                    value: "aws-credentials"
                  - name: cluster-access-secret
                    value: \$(tasks.mapt-provision.results.cluster-access-secret)
                  - name: oci-container
                    value: "not-used-in-successful-run"
                  - name: oci-credentials
                    value: "konflux-test-infra"
          ---
          apiVersion: tekton.dev/v1
          kind: PipelineRun
          metadata:
            name: test-${LOWERCASE_CLUSTER_ID}
          spec:
            pipelineRef:
              name: test-aws-kind-lifecycle
            params:
              - name: id
                value: ${LOWERCASE_CLUSTER_ID}
          EOF

      - name: 12. Monitor PipelineRun for Completion
        env:
          CLUSTER_ID: ${{ env.CLUSTER_ID }}
        run: |
          set -e
          LOWERCASE_CLUSTER_ID=$(echo "$CLUSTER_ID" | tr '[:upper:]' '[:lower:]')
          PIPELINERUN_NAME="test-${LOWERCASE_CLUSTER_ID}"

          echo "Installing jq..."
          sudo apt-get update > /dev/null
          sudo apt-get install -y jq > /dev/null

          echo "Waiting for PipelineRun '${PIPELINERUN_NAME}' to complete..."
          
          for i in {1..120}; do
            SUCCEEDED_CONDITION=$(kubectl get pipelinerun "${PIPELINERUN_NAME}" -n default -o jsonpath='{.status.conditions[?(@.type=="Succeeded")]}' 2>/dev/null)

            if [ -n "$SUCCEEDED_CONDITION" ]; then
              STATUS=$(echo "$SUCCEEDED_CONDITION" | jq -r '.status')
              REASON=$(echo "$SUCCEEDED_CONDITION" | jq -r '.reason')
              MESSAGE=$(echo "$SUCCEEDED_CONDITION" | jq -r '.message')
              
              if [ "$STATUS" == "True" ]; then
                echo "‚úÖ PipelineRun Succeeded."
                kubectl logs --tail=100 -n default -l tekton.dev/pipelineRun=${PIPELINERUN_NAME} --all-containers
                exit 0
              elif [ "$STATUS" == "False" ]; then
                echo "::error::PipelineRun Failed. Reason: ${REASON}."
                echo "::error::Message: ${MESSAGE}"
                echo "--- Dumping all logs for failed PipelineRun ---"
                kubectl logs -n default -l tekton.dev/pipelineRun=${PIPELINERUN_NAME} --all-containers --tail=-1 || echo "Could not retrieve container logs."
                echo "--- Dumping PipelineRun YAML ---"
                kubectl get pipelinerun "${PIPELINERUN_NAME}" -n default -o yaml
                echo "--- Dumping TaskRun YAMLs ---"
                kubectl get taskruns -n default -l tekton.dev/pipelineRun=${PIPELINERUN_NAME} -o yaml
                exit 1
              fi
            fi
            
            echo "Still waiting... (Attempt ${i}/120)"
            sleep 10
          done

          echo "::error::PipelineRun timed out after 20 minutes."
          echo "--- Dumping logs and status for timed out PipelineRun ---"
          kubectl logs -n default -l tekton.dev/pipelineRun=${PIPELINERUN_NAME} --all-containers --tail=-1 || echo "Could not retrieve container logs."
          echo "--- Dumping PipelineRun YAML ---"
          kubectl get pipelinerun "${PIPELINERUN_NAME}" -n default -o yaml
          echo "--- Dumping TaskRun YAMLs ---"
          kubectl get taskruns -n default -l tekton.dev/pipelineRun=${PIPELINERUN_NAME} -o yaml
          exit 1

      - name: 13. Cleanup Temporary S3 Bucket
        if: always()
        run: |
          BUCKET_NAME="${{ steps.s3_bucket.outputs.name }}"
          if [ -n "$BUCKET_NAME" ]; then
            echo "üßπ Cleaning up S3 bucket '$BUCKET_NAME'..."
            aws s3 rb "s3://${BUCKET_NAME}" --force
            echo "‚úÖ Cleanup complete."
          fi
